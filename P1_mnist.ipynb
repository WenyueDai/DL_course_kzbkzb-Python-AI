{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e7c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# 设置硬件设备，如果有GPU则使用，没有则使用cpu\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96a814",
   "metadata": {},
   "source": [
    "## 第一步：前期准备\n",
    "导入 PyTorch、torchvision、matplotlib 等包\n",
    "\n",
    "设置设备：GPU 如果有就用，没的话用 CPU\n",
    "\n",
    "```python\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "\n",
    "## 第二步：加载数据\n",
    "使用 torchvision.datasets.MNIST() 下载并加载数据\n",
    "\n",
    "DataLoader 用来分批次加载数据（batch size = 32）\n",
    "\n",
    "```python\n",
    "train_ds = torchvision.datasets.MNIST('data', train=True, transform=..., download=True)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "```\n",
    "\n",
    "## 第三步：构建神经网络（CNN）\n",
    "用 nn.Sequential 一次性定义网络结构（卷积、池化、全连接等）\n",
    "\n",
    "```python\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    ...\n",
    ").to(device)\n",
    "```\n",
    "\n",
    "## 第四步：训练模型\n",
    "\n",
    "清空梯度： optimizer.zero_grad()\n",
    "计算损失反向传播： loss.backward()\n",
    "更新权重： optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bca70a",
   "metadata": {},
   "source": [
    "<table><tr><td>torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e3571",
   "metadata": {},
   "source": [
    "- root: 数据地址\n",
    "- train: True - training set; False - test set\n",
    "- download: True - download from oneline\n",
    "- transform: 选择数据转化函数\n",
    "- target_transform: 接受目标并对其进行转换的函数/转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9f21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载并加载MNIST数据集\n",
    "train_ds = torchvision.datasets.MNIST('data', \n",
    "                                        train=True, \n",
    "                                        transform=torchvision.transforms.ToTensor(), # 将数据类型转化为Tensor\n",
    "                                        download=True)\n",
    "\n",
    "test_ds  = torchvision.datasets.MNIST('data', \n",
    "                                      train=False, \n",
    "                                      transform=torchvision.transforms.ToTensor(), # 将数据类型转化为Tensor\n",
    "                                      download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a6a06",
   "metadata": {},
   "source": [
    "<table><tr><td>torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=None, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=2, persistent_workers=False, pin_memory_device='')</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7edaef2",
   "metadata": {},
   "source": [
    "- dataset: 加载的数据集\n",
    "- batch_size: 每批加载的样本大小，default=1\n",
    "- shuffle: If True, 每个epoch重新排列数据\n",
    "- sampler: 定义从数据集中抽取样品的策略。\n",
    "- batch_sampler: similar to sampler.\n",
    "- num_workers: 用于数据加载的子进程数。0表示数据将在主进程中加载, default 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b042f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# 创建数据加载器\n",
    "# DataLoader是一个迭代器，可以在训练时按批次加载数据\n",
    "# shuffle=True表示每个epoch都会打乱数据顺序\n",
    "# batch_size指定每个批次的样本数量\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, \n",
    "                                       batch_size=batch_size, \n",
    "                                       shuffle=True)\n",
    "\n",
    "test_dl  = torch.utils.data.DataLoader(test_ds, \n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6891d273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据的shape为：[batch_size, channel, height, weight]\n",
    "# 其中batch_size为自己设定，channel，height和weight分别是图片的通道数，高度和宽度。\n",
    "# 例如MNIST数据集的图片是单通道的28x28灰度图，所以shape为[batch_size, 1, 28, 28]\n",
    "# iter(train_dl) 将数据加载器转换为一个迭代器（iterator），使得我们可以使用 Python 的 next() 函数来逐个访问数据加载器中的元素。\n",
    "# 通过 next() 函数获取第一个批次的数据\n",
    "# 其中 imgs 是一个形状为 [batch_size, 1, 28, 28] 的张量，labels 是一个形状为 [batch_size] 的张量\n",
    "imgs, labels = next(iter(train_dl))\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6437f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    " # 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(imgs[:20]):\n",
    "    imgs = imgs.to(device)  # 将图片数据移动到指定的设备上\n",
    "    imgs = imgs.cpu()  # 将图片数据移动到CPU上，以便进行numpy转换\n",
    "    # np.squeeze() 函数用于去掉数组中维度为1的轴\n",
    "    # 例如，将形状为 [1, 28, 28] 的数组转换为 [28, 28]\n",
    "    # 这样可以方便地将图像数据传递给 matplotlib 进行绘图\n",
    "    npimg = np.squeeze(imgs.numpy())\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52604a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_classes = 10  # 图片的类别数\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"定义一个卷积神经网络模型\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "         # nn.Conv2d为卷积层，用于提取图片的特征，传入参数为输入channel，输出channel，卷积核大小\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  # 第一层卷积,输入通道为1，输出通道为32，卷积核大小为3*3\n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        # nn.MaxPool2d为池化层，进行下采样，用更高层的抽象表示图像特征，传入参数为池化核大小\n",
    "        self.pool1 = nn.MaxPool2d(2)                  # 最大池化层，池化核大小为2*2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) # 第二层卷积,输入通道为32，输出通道为64，卷积核大小为3*3  \n",
    "        self.pool2 = nn.MaxPool2d(2) # 最大池化层，池化核大小为2*2\n",
    "                                      \n",
    "        # 分类网络\n",
    "        # nn.Linear为全连接层，，可以起到特征提取器的作用，最后一层的全连接层也可以认为是输出层，传入参数为输入特征数和输出特征数\n",
    "        # 输入特征数为64，输出特征数为num_classes（10）\n",
    "        # 这里的1600是根据输入图片大小和卷积层、池化层的参数计算得出的。\n",
    "        # 经过两次卷积和池化后，图片的大小从28x28变为4x4，所以输入特征数为64*4*4=1600\n",
    "        self.fc1 = nn.Linear(1600, 64)        \n",
    "        # 第二个全连接层，输入特征数为64，输出特征数为num_classes（10）\n",
    "        # 这里的num_classes是图片的类别数\n",
    "        # 对于MNIST数据集，num_classes=10\n",
    "        # 这意味着模型将输出一个长度为10的向量，每个元素表示对应类别的预测分数\n",
    "        # 最终的分类结果将通过softmax函数转换为概率分布\n",
    "        # softmax函数将输出向量中的每个元素转换为一个概率值，所有概率值的和为1\n",
    "        # 例如，如果输出向量是[2.0, 1.0, 0.5, ..., 0.1]，\n",
    "        # 则softmax函数将其转换为[0.7, 0.2, 0.1, ..., 0.01]，表示模型认为第一个类别的概率为70%，第二个类别的概率为20%，第三个类别的概率为10%，等等。       \n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    # 定义前向传播函数\n",
    "    # 前向传播函数定义了数据如何通过模型进行处理\n",
    "    # 在这个函数中，我们将输入数据通过卷积层、池化层和全连接层进行处理，最终得到输出结果\n",
    "    # 输入参数x是一个形状为 [batch_size, 1, 28, 28] 的张量，表示一批次的图片数据\n",
    "    # 输出结果是一个形状为 [batch_size, num_classes] 的张量，表示每个样本的预测分数\n",
    "    # 其中 batch_size 是每个批次的样本数量，num_classes 是图片的类别数\n",
    "    def forward(self, x):\n",
    "        # 将输入数据通过卷积层和池化层进行处理\n",
    "        # F.relu() 是一个激活函数，用于引入非线性\n",
    "        # 在卷积层之后使用ReLU激活函数可以增加模型的非线性，使得模型能够学习更复杂的特征\n",
    "        # self.pool1 和 self.pool2 是最大池化层，用于下采样特征图，减少特征图的空间维度\n",
    "        # 通过卷积层和池化层的组合，我们可以提取图片中的重要特征\n",
    "        # 经过两次卷积和池化后，\n",
    "        # 图片的大小从28x28变为4x4，所以输出特征图的形状为 [batch_size, 64, 4, 4]\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # 将特征图展平为一维向量\n",
    "        # torch.flatten() 函数用于将多维张量展平为一维\n",
    "        # start_dim=1 表示从第1维开始展平，保留第0维（batch_size）不变\n",
    "        # 这样可以将形状为 [batch_size, 64, 4, 4] 的张量转换为形状为 [batch_size, 64*4*4] 的张量\n",
    "        # 这里的64是输出通道数，4*4是特征图的空间维度\n",
    "        # 展平后的张量可以直接输入到全连接层进行处理\n",
    "        # 经过展平后，张量的形状变为 [batch_size, 1600]\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        # 将展平后的特征向量通过全连接层进行处理\n",
    "        # self.fc1 和 self.fc2 是全连接层，用于将特征向量映射到类别空间\n",
    "        # F.relu() 是一个激活函数，用于引入非线性\n",
    "        # 在全连接层之后使用ReLU激活函数可以增加模型的非线性，使得模型能够学习更复杂的特征\n",
    "        # 最终的输出结果是一个形状为 [batch_size, num_classes] 的张量\n",
    "        # 其中 num_classes 是图片的类别数\n",
    "        # 对于MNIST数据集，num_classes=10\n",
    "        # 这意味着模型将输出一个长度为10的向量，每个元素表示\n",
    "        # 对应类别的预测分数\n",
    "        # 最终的分类结果将通过softmax函数转换为概率分布\n",
    "        # softmax函数将输出向量中的每个元素转换为一个概率值，\n",
    "        # 所有概率值的和为1\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 将激活后的特征向量通过第二个全连接层进行处理\n",
    "        x = self.fc2(x)\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d8f906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Model                                    --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            18,496\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            102,464\n",
       "├─Linear: 1-6                            650\n",
       "=================================================================\n",
       "Total params: 121,930\n",
       "Trainable params: 121,930\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = Model().to(device)\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead12f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "# nn.CrossEntropyLoss() 是一个用于多分类问题的损失函数\n",
    "# 它结合了 softmax 函数和交叉熵损失函数，\n",
    "# 可以直接用于多分类问题的训练\n",
    "# 它的输入是模型的输出（未经过 softmax 函数处理的 logits），\n",
    "# 输出是一个标量，表示模型的损失值\n",
    "# 这个损失函数会自动计算 softmax 函数的输出，并与目标标签进行比较，\n",
    "# 计算出模型的损失值\n",
    "# 这个损失函数适用于多分类问题，特别是当类别数大于2 时\n",
    "# 它可以处理多类别的分类问题，并且可以处理不平衡\n",
    "# 类别的情况\n",
    "# 例如，对于 MNIST 数据集，模型的输出是一个长度为 10 的\n",
    "# 向量，每个元素表示对应类别的预测分数\n",
    "loss_fn    = nn.CrossEntropyLoss() # 创建损失函数\n",
    "\n",
    "# torch.optim.SGD 是一个随机梯度下降优化器，用于更新模型的参数\n",
    "# 它的输入是模型的参数和学习率\n",
    "# 学习率是一个超参数，用于控制模型参数更新的步长\n",
    "# 学习率过大会导致模型不收敛，学习率过小会导致模型收敛速度过慢\n",
    "# 在这里，我们将学习率设置为 1e-2，即 0.01\n",
    "# 这个学习率是一个常用的初始学习率，可以根据实际情况进行调整\n",
    "# 优化器会根据损失函数的梯度信息来更新模型的参数\n",
    "# 在每次迭代中，优化器会计算损失函数的梯度\n",
    "# 然后根据学习率和梯度信息来更新模型的参数\n",
    "# 例如，如果模型的参数是 w，损失函数的梯度是 dw，\n",
    "# 那么优化器会将 w 更新为 w - learn_rate * dw\n",
    "# 这样可以使模型的参数朝着最小化损失函数的方向更新\n",
    "# 这里的 learn_rate 是一个超参数，用于控制模型参数更新的步长\n",
    "# 在训练过程中，我们会不断地使用优化器来更新模型的参数，\n",
    "# 以使模型的损失函数逐渐减小，从而提高模型的性能\n",
    "learn_rate = 1e-2 # 学习率\n",
    "\n",
    "# 创建优化器\n",
    "# torch.optim.SGD 是一个随机梯度下降优化器，用于更新模型的参数        \n",
    "opt= torch.optim.SGD(model.parameters(),lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b255e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"    训练函数\n",
    "    :param dataloader: 数据加载器\n",
    "    :param model: 待训练的模型\n",
    "    :param loss_fn: 损失函数\n",
    "    :param optimizer: 优化器\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)  # 训练集的大小，一共60000张图片\n",
    "    num_batches = len(dataloader)   # 批次数目，1875（60000/32）\n",
    "\n",
    "    train_loss, train_acc = 0, 0  # 初始化训练损失和正确率\n",
    "    \n",
    "    for X, y in dataloader:  # 获取图片及其标签\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 计算预测误差\n",
    "        pred = model(X)          # 网络输出\n",
    "        loss = loss_fn(pred, y)  # 计算网络输出和真实值之间的差距，targets为真实值，计算二者差值即为损失\n",
    "        \n",
    "        # 反向传播\n",
    "        # optimizer.zero_grad() 用于将优化器中的梯度清零\n",
    "        # loss.backward() 用于计算损失函数的梯度\n",
    "        # optimizer.step() 用于更新模型的参数\n",
    "        # 这三个步骤是训练模型的核心部分\n",
    "        # 在每次迭代中，我们需要清零梯度，计算梯度，\n",
    "        # 然后更新模型的参数\n",
    "        # 这样可以使模型的参数朝着最小化损失函数的方向更新参数\n",
    "        # optimizer.zero_grad() 用于将优化器中的梯度清零\n",
    "        # 这一步是为了避免梯度累积，因为在每次迭代中，\n",
    "        # 优化器会将梯度累积到之前的梯度上\n",
    "        # 如果不清零梯度，梯度会不断累积，导致模型参数更新不正确\n",
    "        # loss.backward() 用于计算损失函数的梯度\n",
    "        # 这一步是为了计算损失函数对模型参数的梯度\n",
    "        # 通过计算梯度，我们可以知道模型参数应该如何更新\n",
    "        # optimizer.step() 用于更新模型的参数\n",
    "        # 这一步是根据损失函数的梯度信息来更新模型的参数\n",
    "        # 优化器会根据学习率和梯度信息来更新模型的参数\n",
    "        # 例如，如果模型的参数是 w，损失函数的梯度是 dw\n",
    "        # 那么优化器会将 w 更新为 w - learn_rate * dw\n",
    "        # 这样可以使模型的参数朝着最小化损失函数的方向更新参数\n",
    "        optimizer.zero_grad()  # grad属性归零\n",
    "        loss.backward()        # 反向传播\n",
    "        optimizer.step()       # 每一步自动更新\n",
    "        \n",
    "        # 记录acc与loss\n",
    "        # pred.argmax(1) 返回每个样本预测的类别索引\n",
    "        # y 是每个样本的真实类别标签\n",
    "        # (pred.argmax(1) == y) 返回一个布尔张量，表示每个样本的预测是否正确\n",
    "        # .type(torch.float) 将布尔张量转换为浮点数张量\n",
    "        # .sum().item() 计算正确预测的样本数量\n",
    "        # train_acc 记录正确预测的样本数量, 是正确预测的样本数量除以训练集的大小\n",
    "        # train_loss 记录当前批次的损失值,是所有批次的损失值之和除以批次数\n",
    "        # 这样可以得到训练集上的平均正确率和平均损失\n",
    "        # 最终的 train_acc 和 train_loss 分别表示训练集上的正确率和平均损失,可以用来评估模型的性能\n",
    "        # 如果训练集上的平均正确率较高，平均损失较低\n",
    "        # 说明模型在训练集上表现良好，能够较好地拟合数据\n",
    "        # 如果训练集上的平均正确率较低，平均损失较高\n",
    "        # 说明模型在训练集上表现较差，可能存在过拟合或欠拟合的情况\n",
    "        # 训练集上的平均正确率和平均损失可以用来调整模型的超参数\n",
    "        # 例如，可以通过调整学习率、批次大小、网络结构等超参数来提高模型在训练集上的性能\n",
    "        # 训练集上的平均正确率和平均损失可以用来监控模型的训练过程\n",
    "        # 在每个epoch结束时，可以打印训练集上的平均正确率和平均损失，以便观察模型的训练情况\n",
    "        # 如果训练集上的平均正确率逐渐提高，平均损失逐渐降低\n",
    "        # 说明模型在训练过程中逐渐学习到了数据的特征\n",
    "        # 如果训练集上的平均正确率没有明显变化，平均损失没有明显降低\n",
    "        # 说明模型可能已经收敛，或者存在过拟合或欠拟合的情况\n",
    "        # 在这种情况下，可以尝试调整模型的超参数，或者使用更复杂的模型来提高模型的性能\n",
    "        # 训练集上的平均正确率和平均损失可以用来评估模型\n",
    "        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        train_loss += loss.item()\n",
    "            \n",
    "    train_acc  /= size\n",
    "    train_loss /= num_batches\n",
    "\n",
    "    return train_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70510a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def test (dataloader, model, loss_fn):\n",
    "    \"\"\"测试函数\n",
    "    :param dataloader: 数据加载器\n",
    "    :param model: 待测试的模型\n",
    "    :param loss_fn: 损失函数\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)  # 测试集的大小，一共10000张图片\n",
    "    num_batches = len(dataloader)          # 批次数目，313（10000/32=312.5，向上取整）\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # 当不进行训练时，停止梯度更新，节省计算内存消耗\n",
    "    with torch.no_grad():\n",
    "        for imgs, target in dataloader:\n",
    "            imgs, target = imgs.to(device), target.to(device)\n",
    "            \n",
    "            # 计算loss\n",
    "            target_pred = model(imgs)\n",
    "            loss        = loss_fn(target_pred, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "\n",
    "    test_acc  /= size\n",
    "    test_loss /= num_batches\n",
    "\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "# 训练模型的过程包括多个epoch，每个epoch包含多个批次（batch）\n",
    "epochs     = 5\n",
    "train_loss = []\n",
    "train_acc  = []\n",
    "test_loss  = []\n",
    "test_acc   = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 每个epoch开始时，先将模型设置为训练模式\n",
    "    # 这会启用模型中的一些特定于训练的功能，例如 dropout 和 batch normalization\n",
    "    model.train()\n",
    "    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, opt)\n",
    "    \n",
    "    \n",
    "    model.eval() # 将模型设置为评估模式\n",
    "    # 在评估模式下，模型不会进行梯度更新，也不会启用 dropout\n",
    "    # 这使得模型在测试集上的表现更加稳定\n",
    "    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn) \n",
    "    \n",
    "    train_acc.append(epoch_train_acc)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    test_acc.append(epoch_test_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    \n",
    "    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%，Test_loss:{:.3f}')\n",
    "    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, epoch_test_acc*100, epoch_test_loss))\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
